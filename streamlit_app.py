import streamlit as st
from openai import OpenAI

st.set_page_config(page_title="DeepSeek AI èŠå¤©", page_icon="ğŸ¤–")
st.title("ğŸ¤– DeepSeek AI èŠå¤©æœºå™¨äºº")

# ä¾§è¾¹æ è¾“å…¥API Key
with st.sidebar:
    st.header("è®¾ç½®")
    api_key = st.text_input("DeepSeek API Key", type="password")
    st.markdown("[è·å–API Key](https://platform.deepseek.com/api_keys)")
    
    if st.button("æ£€æŸ¥è¿æ¥"):
        if api_key:
            try:
                client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
                st.success("âœ… è¿æ¥æˆåŠŸï¼")
            except:
                st.error("âŒ è¿æ¥å¤±è´¥")

# åˆå§‹åŒ–èŠå¤©å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# èŠå¤©è¾“å…¥
if prompt := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    if not api_key:
        st.error("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥API Key")
        st.stop()
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # è·å–AIå›å¤
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹"}] + st.session_state.messages[-10:],
            stream=True
        )
        
        for chunk in response:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                message_placeholder.markdown(full_response + "â–Œ")
        
        message_placeholder.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})
